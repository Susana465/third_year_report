[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "3rd Year Report",
    "section": "",
    "text": "Preface\nThis year has been mostly focused on building up knowledge on how to put into action the idea of making a more ethical and reproducible PhD. In order to understand the progress I have made this year, I describe in the following capters the importance of thinking about ethics and reproducibility, what are and how to use Data Hazards, as well as a breakdown of creating reproducible computer models.\nAt this point in time I am in a place where I have started writing my thesis in ways which allow me to keep good version control, which helps manage the source code and documents by keeping track of all the version modifications. In fact, I am using this year’s annual report as an exercise to write an example book using Quarto, which allows for a dynamic implementation of markdown files and python code all in one project, which can be version controlled via Git."
  },
  {
    "objectID": "index.html#this-is-a-quarto-book",
    "href": "index.html#this-is-a-quarto-book",
    "title": "3rd Year Report",
    "section": "This is a Quarto Book:",
    "text": "This is a Quarto Book:\nThis document is written using a Quarto book. Quarto allows for a dynamic implementation of different types of files that can be version controlled, which is extremely helpful to create a pipeline of work all in one place and that is traceable too.\nQuarto® is an open-source scientific and technical publishing system built on Pandoc. It allows you to weave together narrative text and code to produce elegantly formatted output as documents, web pages, blog posts, books and more.\nQuarto is at its core multi-language and multi-engine (supporting Knitr, Jupyter, and Observable today and potentially other engines in the future); where you can have all your code and narrative text in one. For a full breakdown and FAQs of how Quarto works, you can have a look here.\nThe good thing for me personally, is that, thanks to Quarto, I can write my thesis chapters using markdown -which is a lot more intuitive than LaTeX, in my opinion. Moreover, it allows for much better version control compared to Microsoft Word, and allows for helpful traceability of materials included in the document I am writing; which in itself has many benefits as it immensely helps to be able to go back to a previous version where everything was working before I broke the code (yet again).\nPart of my work includes work which runs with different python scripts, and using Quarto means that I can embed python code if needed to explain how certain functionalities of the models work. It also allows for code using R to run within a Quarto document, as well as jupyter notebooks, and includes HTML implementations, which can all help with functionalities such as creating tables, adding images, and rendering the document in different formats (website html, or pdf, for example)."
  },
  {
    "objectID": "index.html#different-modes-to-view-this-report",
    "href": "index.html#different-modes-to-view-this-report",
    "title": "3rd Year Report",
    "section": "Different modes to view this report",
    "text": "Different modes to view this report\n\nIn an internet browser: through this url.\nIn .pdf format: If you are viewing this document in your browser through a url, you can click on the top left icons of the document to download it.\nSource code in GitHub: You can also click on the top left icons of the document to access the source code."
  },
  {
    "objectID": "10-whatsmyphd.html#an-overview",
    "href": "10-whatsmyphd.html#an-overview",
    "title": "1  What is my PhD research question?",
    "section": "1.1 An overview:",
    "text": "1.1 An overview:\nWhen studying learning and memory at the molecular level, in health and disease, it has been shown that NMDAR and CaMKII together with their interactions with other proteins within neuronal spines, can influence their shape and size (Fink and Meyer 2002). Long-term modifications of synaptic strength, such as LTD (Long Term Depression) and LTP (Long Term Potentiation) involve diverse chemical pathways and have been the primary mechanisms used to study the molecular basis of learning and memory (Blundon and Zakharenko 2008). So what exactly is happening at the cellular and molecular level during memory formation?\nThese are the biological prompts that I look at when creating 3D models of the molecules in question. I use mainly mcell and python to do so. In order to give you a better overview of the aims, types of data used, methods and applications of this research, please see below Table 1.1. In addition to the biological aspects of this PhD, as mentioned above, I have made a big effort into making my PhD accessible, reproducible and more ethical. It has transformed into a case study example of how to establish procedures for more ethical and reproducible research, which means future researchers can efficiently re-use and build up on what I have created.\n\n\nTable 1.1: PhD overview\n\n\n\n\n\nWide-view angle of this PhD project\n\n\n\n\nAims of this PhD:\n\n\n- Explain how specific molecules work together during memory. - Develop new ways of 3D modelling to look at time and space dynamics of molecular interactions.  - Bring awareness of the importance of implementing ethics and reproducibility into a PhD.\n\n\nType of data used:\n\n\n- Kinetic rates of molecule interactions, molecular concentrations collected frm literature and databases.  - Numbers obtained from either wet-pab experiments or mathematically calculated.\n\n\nMethods:\n\n\n- Models written with standardised open source languages: python, bionetgen Language.  - Numbers obtained from either wet-pab experiments or mathematically calculated.  - Run locally or in cluster if simulations are more computationally expensive.\n\n\nApplications and significance:\n\n\n- Other researchers can build from these models to create further predictions for potential pharmacological applications.  - Dysregulation of the molecules I look at have been suggested to have a potential impact in Alzheimer’s disease, as well associated with multiple forms of spineopathies (Ghosh and Giese 2015), (Robison 2014).\n\n\n\n\nSo that you can get a better idea of what the modelling might look like, I drew Figure 1.1, which shows a somewhat simplified version of what the graphical user interface of CellBlender can look like. It includes molecules and reactions going in, as well as placement in a 3D cell.\nTLDR: I create 3D models which simulate interactions between CaMKII and NMDAR in the postsynaptic neuron, to understand how memory works in animal brains."
  },
  {
    "objectID": "10-whatsmyphd.html#why-use-computational-modelling-to-study-biological-systems",
    "href": "10-whatsmyphd.html#why-use-computational-modelling-to-study-biological-systems",
    "title": "1  What is my PhD research question?",
    "section": "1.2 Why use Computational Modelling to study biological systems?",
    "text": "1.2 Why use Computational Modelling to study biological systems?\nSome of the main reasons for using modelling are:\n\nBiological systems are complex and multiscale, models can help us to integrate experimental data, facilitating theoretical hypotheses, and addressing what if questions.\nModels aim to make clear the current state of knowledge regarding a particular system, by attempting to be precise about the elements involved and the interactions between them. Doing this can be an effective way to highlight gaps in understanding.\nRelated to point one, models then serve to combine knowledge from different published research, and make biological predictions which can then serve as hypothesis to be tested empirically by experimentalists.\nComputer-simulated experiments can help guide the wet-lab process by narrowing the experimental search space, enabling more cost, time-effective and waste-free research, as well as more ethical research too as we reduce animal suffering through reduction of animal research.\n\n\n\n\nFigure 1.1: A 3D model of a postsynaptic dendritic head, in a schematic of what CellBlender looks like, simplified.\n\n\n\n\n\n\nBlundon, Jay A., and Stanislav S. Zakharenko. 2008. “Dissecting the Components of Long-Term Potentiation.” Neuroscientist 14 (6): 598–608. https://doi.org/10.1177/1073858408320643.\n\n\nFink, Charles C., and Tobias Meyer. 2002. “Molecular Mechanisms of CaMKII Activation in Neuronal Plasticity.” Curr Opin Neurobiol 12 (3): 293–99. https://doi.org/10.1016/s0959-4388(02)00327-6.\n\n\nGhosh, Anshua, and Karl Peter Giese. 2015. “Calcium/Calmodulin-Dependent Kinase II and Alzheimer’s Disease.” Molecular Brain 8 (1): 78. https://doi.org/10.1186/s13041-015-0166-2.\n\n\nRobison, A. J. 2014. “Emerging Role of CaMKII in Neuropsychiatric Disease.” Trends in Neurosciences 37 (11): 653–62. https://doi.org/10.1016/j.tins.2014.07.001."
  },
  {
    "objectID": "20-ethics_reproducible.html#science-for-the-profit-of-whom",
    "href": "20-ethics_reproducible.html#science-for-the-profit-of-whom",
    "title": "2  Ethics and Reproducibility emphasis in this PhD and why it matters",
    "section": "2.1 Science for the profit of whom?",
    "text": "2.1 Science for the profit of whom?\nThere is a historical heritage of monetary incentivization to move towards drug discovery and the profit that comes from this, and how this has played a key role in biasing research towards drug discovery to “fix” individuals, without their wellbeing being necessarily at the forefront. Dosi et al. (2023) provide an long term review of Big Pharma and monopoly capitalism, but there are many examples of how companies move scientific research in a way that is driven by economic profit; and how there’s a constant pull to publish more and publish first. It is not the point of this report to go in depth into how or why this has happened, but I can offer you a few good places to start, if you are interested.\nThe book Warp and Weft by Fennen (2021), with a focus on psychiatry and neuroscience, looks at some of these sciences’ history and examines the ways they have been, and continue to be used as a colonial force. Enforcing a global North science on to the world, as well as describing how many times this enforcement has been led by economic profit for only a few. One good example it cross-references is the “The Mega-Marketing of Depression in Japan” by GlaxoSmithKline, originally spoken about in the book Crazy Like Us by Watters (2010), which is another good place to find examples of this kind.\n\n2.1.1 Historical oppressive biases:\nIt is because of these histories, that I want to attend to them in the work that I do. If we ignore thinking about the ethics, philosophy and history of the research that we do, we may forget where certain ontologies and basis of knowledge come from. Therefore continuing to pretend that these topics are not necessary to think about, whilst a privileged group continues to perpetuate oppressive biases towards historically marginalized groups.\nIn a presentation I gave in 2022, I give a few examples of biases that continue to happen in science, including examples of racism, sexism, ableism and speciesism (Garcia, Sterratt, and Stefan 2022). A good example of embedded biases in science is given by Branch et al. (2022) as they eloquently articulate how a desire to quantify and establish hierarchies among organisms was not purely for scientific interest, but that there is extensive evidence in the fact that the roots of evolutionary biology, which serves as a baseline for many other disciplines like neuroscience, are steeped in histories of white-supremacism, eugenics,and scientific racism. They discuss the definition of the “Not-So-Fit”, and how this limits the diverse thought and investigative potential in biology. This is of importance for my PhD, as I use hierarchies and models of biology that are based on a historical context of how science has reached it’s current status of knowledge."
  },
  {
    "objectID": "20-ethics_reproducible.html#slowing-down",
    "href": "20-ethics_reproducible.html#slowing-down",
    "title": "2  Ethics and Reproducibility emphasis in this PhD and why it matters",
    "section": "2.2 Slowing down…",
    "text": "2.2 Slowing down…\nAs a response to a fast-paced, profit-driven science, a few Slow Science Manifestos have been published, notably Another Science is Possible: A Manifesto for Slow Science by Stengers (2018) maintains that in order to make higher quality education and science, it needs to serve society as a whole, and calls, among other things, for an “accountability in the knowledge society versus profitability in the knowledge economy”.\nMoreover, as long as we continue to create fast research without regard for reproducibility, we will continue to experience what some now call a “Reproducibility Crisis” (Baker 2016), (Treves 2022), where we find that, as work is done into trying to reproduce previous published results, this is not possible. The reproducibility or replicability crisis (more on these terms below) undermines the credibility of theories scientific knowledge; as an essential part of the scientific part of the scientific method is to be able to repeat and reproduce or falsify empirical results and theories.\nThere is an argument to be made that making research more reproducible and ethical takes more time. And it does. This is precisely why slowing down can help in creating higher quality research that serves all in society."
  },
  {
    "objectID": "20-ethics_reproducible.html#importance-of-reproducibility",
    "href": "20-ethics_reproducible.html#importance-of-reproducibility",
    "title": "2  Ethics and Reproducibility emphasis in this PhD and why it matters",
    "section": "2.3 Importance of reproducibility",
    "text": "2.3 Importance of reproducibility\nDuring my PhD work so far, one aspect of the research that has come with quite a lot of struggle is to find accurate parametrization of values for protein dynamics. This is a known issue for most of us who create computational models of biological systems. Wieber and Hocquet (2020) call it an “epistemic opacity” when talking about lack of clarity in Computational Chemistry, where this opacity is entangled in methods and software alike.\nThis of course leads to reproducibility issues, and as this unfolds, it becomes clear that the “untrustworthiness” of research is also an issue for many other researchers. In fact, a survey of 1576 scientists published in Nature (Baker 2016) reported that over 70% of the participants failed to reproduce others’ experiments and over 50% failed to reproduce their own results.\nInterestingly, Tiwari et al. (2021), assessed the reproducibility of 455 mathematical models in systems biology and found that about 50% of published models were not reproducible either due to incorrect or missing information in the manuscript.\nMaking an effort into creating research that is reproducible can help to avoid wasting resources, including having to repeat the same experiment questions again and again because results from one study could not be reproduced or replicated by other groups.\n\n2.3.1 Defining reproducibility vs replicability\nThese terms have been used interchangeably for a while, or their meanings being swapped depending on the field of study Claerbout and Karrenbach (1992)], (Ivie and Thain 2018), (Plesser 2018).\nHere, we use the definition used by (Turing Way Community et al. 2019), where reproducible research is understood as work that can be independently recreated from the same data and the same code that the original team used. Reproducible is distinct from replicable, robust and generalisable as described in the table below (Figure 2.1).\n\n\n\nFigure 2.1: How the Turing Way defines reproducible research.\n\n\nThe different dimensions of reproducible research described in the matrix above have the following definitions, taken from the Turing Way booklet:\n\nReproducible: A result is reproducible when the same analysis steps performed on the same dataset consistently produces the same answer.\nReplicable: A result is replicable when the same analysis performed on different datasets produces qualitatively similar answers.\nRobust: A result is robust when the same dataset is subjected to different analysis workflows to answer the same research question (for example one pipeline written in R and another written in Python) and a qualitatively similar or identical answer is produced. Robust results show that the work is not dependent on the specificities of the programming language chosen to perform the analysis.\nGeneralisable: Combining replicable and robust findings allow us to form generalisable results. Note that running an analysis on a different software implementation and with a different dataset does not provide generalised results. There will be many more steps to know how well the work applies to all the different aspects of the research question. Generalisation is an important step towards understanding that the result is not dependent on a particular dataset nor a particular version of the analysis pipeline."
  },
  {
    "objectID": "20-ethics_reproducible.html#ethics-and-reproducibility-go-together",
    "href": "20-ethics_reproducible.html#ethics-and-reproducibility-go-together",
    "title": "2  Ethics and Reproducibility emphasis in this PhD and why it matters",
    "section": "2.4 Ethics and Reproducibility go together",
    "text": "2.4 Ethics and Reproducibility go together\nEntangled with reproducibility, is thinking about ethics. Because no matter how efficient and reproducible an outcome may be, if it’s harming a group of individuals, how good really is this research? Likewise, if a project has taken into account and described potential bias and harms of their data, but then does not share enough material for their research to be reproduced by others, are we really advancing?\nThinking about reproducibility can in turn help to think how you will share your data, as well as where your own data has come from. Hence, reaching an increased awareness of how your data was sourced and its ethics and potential biases. In order to showcase how I see these topics as being interwoven, I presented a poster titled “Bias and reproducibility in a computational neurobiology PhD’s journey” (Figure 2.2) at the International Conference on Systems Biology (ICSB) in October 2022. On the left side of the poster, I share how to think about the ethics and bias of your research, and on the right side I provide tools for reproducibility. I also wrote about this more in depth in this GitHub repository here.\nI created this poster because I wanted to showcase, at a conference full of scientists at different stages of their research, how I take into account bias an reproducibility in my research, and how they could too.\n\n\n\nFigure 2.2: Poster about bias and reproducibility, showing research cycle as a journey which starts with design, then data collection, data analysis and final reporting, and compares this through images to growing an apple tree, collecting the apples and then selling them.\n\n\nWorking with ethics, philosophy, reproducibility and an openness to discuss the wider context of where our research rests, may add a bit of time to the research timeline, but can very much enrich a fuller and more complex understanding of the shortcomings of our research and how to do better moving forward.\nFollowing on the idea that scientists are great at selling the gains in efficiency and accuracy of their work, but less well-practiced in thinking about the ethical implications of our work, I present a framework developed to think about dangers or risks involved with your data and research: Data Hazard Labels, see following Chapter 3.\n\n\n\n\nBaker, Monya. 2016. “1,500 Scientists Lift the Lid on Reproducibility.” Nature 533 (7604, 7604): 452–54. https://doi.org/10.1038/533452a.\n\n\nBranch, Haley A., Amanda N. Klingler, Kelsey J. R. P. Byers, Aaron Panofsky, and Danielle Peers. 2022. “Discussions of the ‘Not So Fit’: How Ableism Limits Diverse Thought and Investigative Potential in Evolutionary Biology.” The American Naturalist 200 (1): 101–13. https://doi.org/10.1086/720003.\n\n\nClaerbout, Jon F., and Martin Karrenbach. 1992. “Electronic Documents Give Reproducible Research a New Meaning.” In SEG Technical Program Expanded Abstracts 1992, 601–4. SEG Technical Program Expanded Abstracts. Society of Exploration Geophysicists. https://doi.org/10.1190/1.1822162.\n\n\nDelgado, Nick. 2022. “Owning Your Privilege: Leaving Guilt, Shame, and Blame Behind.” Integrated Work. February 15, 2022. https://integratedwork.com/jedi/owning-your-privilege/.\n\n\nDiAngelo, Dr Robin. 2018. White Fragility: Why It’s So Hard for White People to Talk About Racism. Beacon Press. https://books.google.com?id=abZdDwAAQBAJ.\n\n\nDiogo, Rui, Adeyemi Adesomo, Kimberly S. Farmer, Rachel J. Kim, and Fatimah Jackson. 2023. “Not Just in the Past: Racist and Sexist Biases Still Permeate Biology, Anthropology, Medicine, and Education.” Evolutionary Anthropology: Issues, News, and Reviews 32 (2): 67–82. https://doi.org/10.1002/evan.21978.\n\n\nDosi, Giovanni, Luigi Marengo, Jacopo Staccioli, and Maria Enrica Virgillito. 2023. “Big Pharma and Monopoly Capitalism: A Long-Term View.” Structural Change and Economic Dynamics 65 (June): 15–35. https://doi.org/10.1016/j.strueco.2023.01.004.\n\n\nFennen, Lisa. 2021. Warp & Weft; Psycho-Emotional Health, Politics and Experiences. https://lisafannen.bandcamp.com/album/warp-weft.\n\n\nGarcia, Susana Roman, David Sterratt, and Melanie Stefan. 2022. “Thinking about Ethics in (Computer) Science.” University of Edinburgh, Edinburgh, August 8. https://doi.org/10.5281/zenodo.6973796.\n\n\nIvie, Peter, and Douglas Thain. 2018. “Reproducibility in Scientific Computing.” ACM Comput. Surv. 51 (3): 63:1–36. https://doi.org/10.1145/3186266.\n\n\nPlesser, Hans E. 2018. “Reproducibility Vs. Replicability: A Brief History of a Confused Terminology.” Frontiers in Neuroinformatics 11. https://www.frontiersin.org/articles/10.3389/fninf.2017.00076.\n\n\nStengers, Isabelle. 2018. Another Science Is Possible: A Manifesto for Slow Science. John Wiley & Sons. https://books.google.com?id=oxJSDwAAQBAJ.\n\n\nTiwari, Krishna, Sarubini Kananathan, Matthew G. Roberts, Johannes P. Meyer, Mohammad Umer Sharif Shohan, Ashley Xavier, Matthieu Maire, et al. 2021. “Reproducibility in Systems Biology Modelling.” Mol Syst Biol 17 (2): e9982. https://doi.org/10.15252/msb.20209982.\n\n\nTreves, Adrian. 2022. “‘Best Available Science’ and the Reproducibility Crisis.” Frontiers in Ecology and the Environment 20 (9): 495–95. https://doi.org/10.1002/fee.2568.\n\n\nTuring Way Community, The, Louise Bowler, Sarah Gibson, Patricia Herterich, Rosie Higman, Anna Krystalli, Alexander Morley, Martin O’Reilly, and Kirstie Whitaker. 2019. “The Turing Way: A Handbook for Reproducible Data Science.” Zenodo. https://doi.org/10.5281/zenodo.3233986.\n\n\nWatters, Ethan. 2010. Crazy Like Us: The Globalization of the American Psyche. New York: Free Pr.\n\n\nWebb, E. Kate, J. Arthur Etter, and Jasmine A. Kwasa. 2022. “Addressing Racial and Phenotypic Bias in Human Neuroscience Methods.” Nat Neurosci 25 (4, 4): 410–14. https://doi.org/10.1038/s41593-022-01046-0.\n\n\nWieber, Frederic, and Alexandre Hocquet. 2020. “Models, Parameterization, and Software: Epistemic Opacity in Computational Chemistry.” Published Article or Volume. Perspectives on Science; MIT Press. October 2020. https://doi.org/10.1162/posc_a_00352."
  },
  {
    "objectID": "20-ethics_reproducible.html#footnotes",
    "href": "20-ethics_reproducible.html#footnotes",
    "title": "2  Ethics and Reproducibility emphasis in this PhD and why it matters",
    "section": "",
    "text": "This bias towards benefiting cis-male, white, able-bodied people does not mean they do not suffer, and does not negate the existence of the issues they may experience too. For more information on how society is biased in a way that provides privileges in a certain order/hierarchy, and how to handle it, please have a look at (DiAngelo 2018),or (Delgado 2022).↩︎"
  },
  {
    "objectID": "30-data_hazards.html#example-label-high-environmental-cost",
    "href": "30-data_hazards.html#example-label-high-environmental-cost",
    "title": "3  Data Hazards",
    "section": "3.1 Example label: high environmental cost",
    "text": "3.1 Example label: high environmental cost\n\n\n\nFigure 3.1: “High Environmental Impact” Data Hazard Label\n\n\n\n3.1.1 Description\nThis hazard is appropriate where methodologies are energy-hungry, data-hungry (requiring more and more computation), or require special hardware that require rare materials.\n\n\n3.1.2 Examples\n\nExample: Running computer models in super computers requires vast energy usage.\n\n\n\n3.1.3 Safety Precautions\n\nConsider in what circumstances it is worthwhile to use this type of methodology.\n\nTo communicate the scale of the issue to other stakeholders, you may want to convert units of energy into more relatable units.\nFind out if your cloud provider uses renewable energy.\nConsider profiling your code, and rewriting it to use less energy.\n\nConsider future work that would reduce the need to use increasingly more resources."
  },
  {
    "objectID": "30-data_hazards.html#how-to-use-the-data-hazards-project",
    "href": "30-data_hazards.html#how-to-use-the-data-hazards-project",
    "title": "3  Data Hazards",
    "section": "3.2 How to use the Data Hazards Project",
    "text": "3.2 How to use the Data Hazards Project\nThere are four steps to using the Data Hazard labels:\n\nLearning: familiarising yourself with the Data Hazard labels.\nApplying: deciding which Hazard labels are relevant to your project.\nReflecting: on what to do differently and what mitigations to make.\nDisplay: displaying the labels alongside your work can help you to communicate that you’ve thought about these broad ethical issues and how you’d like others to use your work.\n\nThis spells LARD 🧈, which makes it pretty easy to remember! It is however an unfortunate word it shortens to, as lard comes from dead pigs, so I like to manifest it’s a plant-based LARD 🌱.\nAs part of a Turing Way Book Dash hosted in May 2023, I worked together with a team to create a chapter on Data Hazards for the Turing Way Book. This chapter is still in draft form, but one of the fun things got to do was to work with an artist from Scriberia, to make an illustration of the Data Hazards application (Figure 3.2).\n\n\n\nFigure 3.2: Data Hazards Application Cycle (Community and Scriberia 2023)."
  },
  {
    "objectID": "30-data_hazards.html#application-example-into-research-life-cycle",
    "href": "30-data_hazards.html#application-example-into-research-life-cycle",
    "title": "3  Data Hazards",
    "section": "3.3 Application example into Research life-cycle",
    "text": "3.3 Application example into Research life-cycle\nTo help visualize where and when Data Hazards can be used in your workflow, below is an example assuming four main stages of workflow: design, data collection, data analysis and reporting. This is a generalised example, but something like this is what it looks like for me when I work on my PhD.\n\n3.3.1 Design:\n\nAre you using data? Then doing some reflection on identity and positionality could help you think of what Data Hazards labels you might encounter as you design your project, for example “ranks of classifies people hazard” or “risk to privacy” could apply at this stage.\nIn this part of the workflow, you might want to prepare to avoid certain Data Hazards if you can, and if you can’t avoid them because of where your data has come from, you may want to acknowledge this. For example, if you a sensitive data project, what Data Hazard labels will apply, and/or what can you do to design your project in a way that avoids certain harms?\n\n\n\n3.3.2 Data Collection and Analysis:\n\nAs you are collecting and analyzing your data, you might want to iteratively think of the potential Data Hazards that exist in the information you are collecting. To then apply the labels as you perform the next step of the process: reporting.\n\n\n\n3.3.3 Reporting:\n\nWhen reporting your results, you can think of applying and reporting the Data Hazard labels that are relevant for your project; examples of how others have done this can be found here [link to self reflection and case studie(s)]. Labeling your project with Data Hazards should also include considerations of mitigations to these risks. This would then be helpful for people who see your outputs in the future. They can be aware of potential risks as they proceed with the project, and continue to think of solutions to any issues related to the research topic."
  },
  {
    "objectID": "30-data_hazards.html#application-into-my-phd-project-presenting-my-phd-as-a-case-study-at-ai-uk-conference",
    "href": "30-data_hazards.html#application-into-my-phd-project-presenting-my-phd-as-a-case-study-at-ai-uk-conference",
    "title": "3  Data Hazards",
    "section": "3.4 Application into my PhD project: Presenting my PhD as a case study at AI UK conference",
    "text": "3.4 Application into my PhD project: Presenting my PhD as a case study at AI UK conference\nIn order to showcase how Data Hazards can be reflected upon during a PhD, and taking the self-reflection described above into consideration, I have been implementing thinking about the vocabulary they provide into my own work. In line with this work, I made a poster that summarised aims of my PhD, for people to be able to say which labels they thought applied to my project. This poster was part of an exhibition stand with the Data Hazards Team, at AI UK 2023.When creating this poster (Figure 3.3), I was able to both do some self-reflection and collaborative reflection, as described below.\n\nSelf-reflection (what is my project and how will it be used?):\n\nWhen making the poster, this kind of self-reflection questions are useful for oneself to think about, but also for external people who are not involved with your project to understand what potential data hazards it might have. The final poster can be seen below in (Figure 3.3). I followed the prompt questions available in the Data Hazards website for project owners who would like their projects to be discussed for data hazards:\n– The overall objective of the project.\n– Fairly detailed description of the variables in the dataset they are using (and what is not included).\n– How and when the data was collected.\n– Any statistical/algorithmic methods being used.\n– Who has input on the project.\n– What outputs are expected, and how these will be shared.\n\nCollaborative reflection (what data hazards may apply to my project?):\n\nThen, during the poster presentation, people would come over and talk about the project, have a look at the poster, and decide by adding stickers to a list of hazards, to say which ones applied to it. You can see below how it looked (Figure 3.4).\nSo, as can be seen in the photo of me happily posing next to the poster Figure 3.4 (before end of the day), people were adding stickers to record which data hazard labels they thought applied to my PhD project. At the end of the day, I recorded final numbers and the results can be seen in the barchart below Figure 3.5.\n\n\n\nFigure 3.3: PhD Project decription - Case Study, to see GitHub repo, click on this figure.\n\n\n\n\n\nFigure 3.4: Data Hazards Case Study Poster at AI UK\n\n\n\n3.4.1 Results from collaborative reflections:\n\nDifficult to understand Label was chosen the most Interestingly, not all labels were chosen as applicable to my project (Figure 3.5). Only 6 of the 11 current labels were chosen as relevant, with “difficult to understand” being the most prevalent one, chosen by 6 people. High environmental impact and danger of misuse follow in closely with 5 people having chosen these ones. Of course these numbers are small and hold, more than anything, illustrative value as to how and why people may think certain labels apply to a project. In the case of my PhD project, which involves understanding of very specific molecules, as well as knowledge of programming and computer modelling software, it makes sense that the “difficult to understand” label was the one people chose the most.\nfind and explain mitigaions for these hardas. show examples of how im thinking to mitigate them.\n\n\n\n\n\n\nFigure 3.5: Data Hazards labels that may apply to my PhD.\n\n\n\n\nMAKE A TABLE OF DATA HAZARDS -md or html or python?\n\nCaption\n\n\n\nData Hazard Description\nSafety Precautions\n\n\n\n\n\nDifficult to understand. There is a danger that the technology is difficult to understand. This could be because of the technology itself is hard to interpret (e.g. neural nets), or problems with it’s implementation (i.e. code is not provided, or not documented). Depending on the circumstances of its use, this could mean that incorrect results are hard to identify, or that the technology is inaccessible to people (difficult to implement or use).\n\nMake research code Open Source with an appropriate software license where possible. Your local Research Software Engineering group may be able to help you with this.\nCompare results to white box (explainable) methods such as Random Forest or Regression, which may perform just as well.\nEnsure code is well documented with accompanying and/or inline documentation.\n\n\n\n\nHigh environmental impact. There is a danger that the technology is difficult to understand. This could be because of the technology itself is hard to interpret (e.g. neural nets), or problems with it’s implementation (i.e. code is not provided, or not documented). Depending on the circumstances of its use, this could mean that incorrect results are hard to identify, or that the technology is inaccessible to people (difficult to implement or use).\n\nMake research code Open Source with an appropriate software license where possible. Your local Research Software Engineering group may be able to help you with this.\nCompare results to white box (explainable) methods such as Random Forest or Regression, which may perform just as well.\nEnsure code is well documented with accompanying and/or inline documentation.\n\n\n\n\nDanger of misuse. There is a danger that the technology is difficult to understand. This could be because of the technology itself is hard to interpret (e.g. neural nets), or problems with it’s implementation (i.e. code is not provided, or not documented). Depending on the circumstances of its use, this could mean that incorrect results are hard to identify, or that the technology is inaccessible to people (difficult to implement or use).\n\nMake research code Open Source with an appropriate software license where possible. Your local Research Software Engineering group may be able to help you with this.\nCompare results to white box (explainable) methods such as Random Forest or Regression, which may perform just as well.\nEnsure code is well documented with accompanying and/or inline documentation.\n\n\n\n\nblablabla where does text and table render in pdf? text to test this"
  },
  {
    "objectID": "30-data_hazards.html#data-hazards-workshops",
    "href": "30-data_hazards.html#data-hazards-workshops",
    "title": "3  Data Hazards",
    "section": "3.5 Data Hazards Workshops",
    "text": "3.5 Data Hazards Workshops\n\nTalk about application of DH into different workshop setups, in COMBINE and Turing Institute.\nMost info available here: https://github.com/Susana465/Data_Hazards_workshops, re-write.\n\n\n\n\n\nCommunity, The Turing Way, and Scriberia. 2023. Illustrations from The Turing Way: Shared Under CC-BY 4.0 for Reuse. Zenodo. https://doi.org/10.5281/zenodo.8169292."
  },
  {
    "objectID": "40-models.html#software-used-bionetgen-and-mcell",
    "href": "40-models.html#software-used-bionetgen-and-mcell",
    "title": "4  Computer models of CaMKII/NMDAR interactions",
    "section": "4.1 Software used: BioNetGen and MCell",
    "text": "4.1 Software used: BioNetGen and MCell\n\n4.1.1 BioNetGen and how rule-based modelling can help with combinatorial complexity.\nBioNetGen is a set of software tools which facilitate a rule-based approach to modelling biochemical reaction kinetics, where we can largely overcome the problem of combinatorial complexity that arises when modelling CaMKII. It has been calculated that CaMKII as a dodecamer can approximately have 1020 possible states (Pharris et al. 2019); this, together with the potential of a full reaction network for each simulation (an added factor of combinatorial complexity), can render the model computationally intractable. BioNetGen can help us deal with this combinatorial complexity thanks to its rule-based modelling (RBM) “don’t care, don’t write” capabilities. And as we will see later MCell can help with modelling network-free simulations.\nBioNetGen language (BNGL) is a formal language which uses the BioNetGen software (Faeder, Blinov, and Hlavacek 2009). It allows for site-specific details of protein-protein interactions to be captured in models for the dynamics of these interactions in a systematic fashion, which also alleviates nomenclature and reusability issues.\nHence, using this RBM approach is notable as it facilitates writing of multi-state modelling and can significantly, reduce the number of reactions that need to be written due to its “don’t write, don’t care” characteristic. Thereby dramatically improving the ability to model CaMKII as a dodecamer; I can make a model with multistate molecules, and specify the states of the reactants that are relevant for a particular reaction, and leave the rest unspecified. Below I provide an example of what a simple BNGL model can look like.\n# BioNetGen code which shows a simple model of A, B,C molecules \\\nthat is helpful for understanding the \"don't care, don't write\" \\\ncapacity of rule based modelling.\n\nbegin model\n\nbegin parameters\n# Define initial number of molecules released\n  A_i 150\n  B_i 150\n  C_i 100\n\n#Define reaction rates\n  kon 1e-2\n  koff 1e-3\n  k_P 1e1\nend parameters\n\nbegin molecule types\n# Define the molecules and the possible states and \\\nbinding sites they can have:\n\n# Molecule A has a binding site (a), and a Phosphorylation site \\\nwhich can be unphosphorylated (~0) or phosphorylated (~P)\n    A(a,T286~0~P)\n# Molecule B has a binding site (b)\n    B(b)\n# Molecule C has no binding sites\n    C()\nend molecule types\n\nbegin species\n# Molecule A starts with binding site a free, \\\nand with phosphorylation site unphosphorylated\n    A(a,T286~0) A_i \n# Molecule B starts with binding site b free\n    B(b) B_i\n# Molecule C has no binding sites so it starts as it is\n    C() C_i\nend species\n\nbegin reaction rules\n# A_free and B_free can resversbly bind to give AB_complex\n# Don't need to specify, if I'm not interested, status of \\\nphosphorylation for molecule A. Note how it is not written \\\nin the rule definition  (don't care, don't write)\n    A(a) + B(b) &lt;-&gt; A(a!1).B(b!1) kon, koff\n\n# If A is unphosphorylated, it can become phoshorylated \\\nby the presence of C. Don't need to specify status of \\ \nbinding site 'a' (don't care, don't write)\n    A(T286~0) + C() -&gt; A(T286~P) k_P\n\nend reaction rules\n\nbegin observables\n  Molecules AB_complex A(a!1).B(b!1)\n  Molecules A_phosphorylated A(T286~P)\n  Molecules A A(a)\n  Molecules B B(b)\n  Molecules C C()\nend observables\n\nend model\nsimulate({method=&gt;\"ssa\",t_end=&gt;10,n_steps=&gt;100})\n\nTo interact with this code, you can have a look and download a jupyter notebook I have created here, where I also describe some of the ways in which the model can be simulated, with stochastic simulation algorithms (SSAs) or ordinary differential equations (ODEs). See screenshot from notebook in Figure 4.1 below.\n\n\n\nFigure 4.1: What an ODE output from the model above looks like, shown as output is created in jupyter notebook.\n\n\n\n\n4.1.2 MCell (Monte Carlo Cell) and how it simulates reactions in 3D\nMCell is a biochemistry simulation tool that uses spatially realistic 3D cellular models and stochastic Monte Carlo algorithms to simulate the movements and interactions of discrete molecules within and between cells, (Bartol and Stiles 2000), (Kerr et al. 2008), (Bartol et al. 2015). MCell is a particle-based simulator that represents molecules as point particles in 3D space. At every time step in an MCell simulation, each particle can move, collide with other particles or surfaces, and undergo bimolecular and unimolecular reactions. The basic elements of a simulation step are as seen in Figure 4.2 taken from Gupta et al. (2018).\n\n\n\nFigure 4.2: MCell Components. (A) Volume Molecules diffusing in free space. (B) Mesh Object defined by a Plane with Surface Molecules diffusing on it. (C) Mesh Object defined by a complex closed mesh with multiple defined Surface Regions, in which Surface Molecules have different diffusion constants, as defined by corresponding Surface Classes.\n\n\nBriefly, MCell operates as follows: as a volume molecule diffuses, all molecules within a given radius along its trajectory, or at the point of collision on a surface, are considered for a reaction. For surface molecules (in membranes), the molecule first diffuses, and then its neighbours are evaluated for reaction.\nThere is no volume exclusion for molecules diffusing in 3D volumes, and molecules on surfaces occupy a fixed area. MCell allows defining arbitrary geometry Figure 4.2 (C), and complex models such as a 180μm3 3DEM reconstruction of hippocampal neuropil have been used to construct a geometrically-precise simulation of 100s of neuronal synapses at once (Bartol et al. 2015). A detailed description of mathematical foundations of MCell’s algorithms can be found here: Bartol and Stiles (2000), Kerr et al. (2008), Bartol et al. (2015).\nMCell4, version used for this project, provides a versatile Python interface, which is very useful for writing models with said interface and running mcell models this way. MCell4 provides two different user experiences, one through its visual interface as an add-on in Blender 2.93, known as CellBlender (see back at Figure 1.1), the other user experience one through a new Python interface. This provides users with the flexibility to change between both experiences, or to run the simulations using Python and visualize the simulations in Blender (Figure 4.3).\n\n\n\nFigure 4.3: Diagram of what workflow of this project can look like, it is not exhaustive of all the ways in which these software can interact. Diagram was made with Lucid."
  },
  {
    "objectID": "40-models.html#model-description",
    "href": "40-models.html#model-description",
    "title": "4  Computer models of CaMKII/NMDAR interactions",
    "section": "4.2 Model description",
    "text": "4.2 Model description\nI have constructed the models at different scales to validate CaMKII interactions with other molecules like calmodulin and NMDARs, at increasing levels of complexity. First I re-created a model of CaMKII as a monomer that was previously completed in 2017. The model created uses cBNGL and represents CaMKII as monomers to serve as a proof of concept as well as a starting validation point, as dynamics of this model were previously shown to be within biologically accurate limits. Secondly, I created a model of CaMKII as a hexamer since modelling this molecule as a dodecamer gave rise to a combinatorial explosion due to the high number of possible states and the network of interactions generated. This was them resolved as I run the model using the network-free simulation capabalities using MCell. This has then resulted in being able to create a (still in the workd) model of CaMKII as a dodecamer. These simulations include only calcium binding to CaM, and CaM binding to CaMKII as a dodecamer, without further reactions added to avoid further complexity. Finally, I aim to validate this work against a model from Ordyan et al., 2020, where they successfully modelled CaMKII as a twelve subunit holoenzyme using BioNetGen simulations.\n\n4.2.1 Model of CaMKII as a dodecamer\nFor brevity’s sake, I have chosen to not go into details of CaMKII, as that was discussed in depth in the pasy 2 yearly reports. CaMKII is a dodecameric molecule, meaning it’s composed of twelve subunits. Modelling it as a dodecamer allow us to infer more accurately any emergent behaviour of the protein."
  },
  {
    "objectID": "40-models.html#model-development-and-validation",
    "href": "40-models.html#model-development-and-validation",
    "title": "4  Computer models of CaMKII/NMDAR interactions",
    "section": "4.3 Model development and validation",
    "text": "4.3 Model development and validation\nFollowing from what I did last year, show results, copy what’s on github https://github.com/Susana465/CaMKII_hexa_bgnl_to_mcell\nDevelop the description of how the models work – model description and results. Biologist friendly description of the model.\ntalk about roustness, generalisable, environments\nWrite abstract for each chapter, then merge them altogether.\n\n4.3.1 A reproducible model\nThe same processes used in software development can also be applied to biological model development. Therefore, when developing the models in this project, four main points were considered throughout, as suggested by Husar et al. (2022):\n\nCreate incremental development where the model is built step by step, relying on solid foundations of modelling done and validated before,\nCreate a modularity that provides the capability to create self-contained, reusable libraries,\nPerform unit testing and validation to verify that parts of the model behave as expected and,\nCreate human-readable and writable model code that can be stored using git or other code version control software which also allows code reviews so that other team members can inspect the latest changes to the model.\n\n\n\n\n\nBartol, Thomas M., Daniel X. Keller, Justin P. Kinney, Chandrajit L. Bajaj, Kristen M. Harris, Terrence J. Sejnowski, and Mary B. Kennedy. 2015. “Computational Reconstitution of Spine Calcium Transients from Individual Proteins.” Frontiers in Synaptic Neuroscience 7. https://www.frontiersin.org/articles/10.3389/fnsyn.2015.00017.\n\n\nBartol, Thomas M., and Joel R Stiles. 2000. Monte Carlo Methods for Simulating Realistic Synaptic Microphysiology Using MCell. Vol. chapter 4. CRC Press. https://books.google.com?id=8TLpBwAAQBAJ.\n\n\nFaeder, James R., Michael L. Blinov, and William S. Hlavacek. 2009. “Rule-Based Modeling of Biochemical Systems with BioNetGen.” Methods Mol Biol 500: 113–67. https://doi.org/10.1007/978-1-59745-525-1_5.\n\n\nGupta, Sanjana, Jacob Czech, Robert Kuczewski, Thomas M. Bartol, Terrence J. Sejnowski, Robin E. C. Lee, and James R. Faeder. 2018. “Spatial Stochastic Modeling with MCell and CellBlender.” September 30, 2018. https://doi.org/10.48550/arXiv.1810.00499.\n\n\nHusar, Adam, Mariam Ordyan, Guadalupe C. Garcia, Joel G. Yancey, Ali S. Saglam, James R. Faeder, Thomas M. Bartol, and Terrence J. Sejnowski. 2022. “MCell4 with BioNetGen: A Monte Carlo Simulator of Rule-Based Reaction-Diffusion Systems with Python Interface.” May 19, 2022. https://doi.org/10.1101/2022.05.17.492333.\n\n\nKerr, Rex A., Thomas M. Bartol, Boris Kaminsky, Markus Dittrich, Jen-Chien Jack Chang, Scott B. Baden, Terrence J. Sejnowski, and Joel R. Stiles. 2008. “FAST MONTE CARLO SIMULATION METHODS FOR BIOLOGICAL REACTION-DIFFUSION SYSTEMS IN SOLUTION AND ON SURFACES.” SIAM J Sci Comput 30 (6): 3126. https://doi.org/10.1137/070692017.\n\n\nPharris, Matthew C., Neal M. Patel, Tyler G. VanDyk, Thomas M. Bartol, Terrence J. Sejnowski, Mary B. Kennedy, Melanie I. Stefan, and Tamara L. Kinzer-Ursem. 2019. “A Multi-State Model of the CaMKII Dodecamer Suggests a Role for Calmodulin in Maintenance of Autophosphorylation.” PLOS Computational Biology 15 (12): e1006941. https://doi.org/10.1371/journal.pcbi.1006941."
  },
  {
    "objectID": "50-activities.html",
    "href": "50-activities.html",
    "title": "5  Activities",
    "section": "",
    "text": "what have i been up to?"
  },
  {
    "objectID": "60-thesis_layout.html",
    "href": "60-thesis_layout.html",
    "title": "6  Thesis layout",
    "section": "",
    "text": "BACKGROUND\n\nResearch question\nReport style and philosophy\nEthics and Reproducibility\n\nScience for the profit of whom?\nImportance of reproducibility\nEthics and reproducibility go together\n\nData Hazards\nMemory and Learning\n\nWhy study CaMKII and NMDAR interactions to study memory formation?\nA brief history background on learning and memory research\nLong Term Potentiation\nNMDA receptors structure and functions\nCaMKII structure and functions\nBringing it all together: LTP, CaMKII/NMDAR complex as a molecular memory and interactions within the postsynaptic neuron\n\nWhy use computational modelling to study biological systems?\n\nHow do we model biochemical systems networks?\nRule Based Modelling\nBioNetGen\nMCell\nBiodynamo\n\n\nMETHODS\n\nModel Description\nModel development and validation\n\nA reproducible model\n\n\nRESULTS"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Baker, Monya. 2016. “1,500 Scientists Lift the Lid on\nReproducibility.” Nature 533 (7604, 7604): 452–54. https://doi.org/10.1038/533452a.\n\n\nBartol, Thomas M., Daniel X. Keller, Justin P. Kinney, Chandrajit L.\nBajaj, Kristen M. Harris, Terrence J. Sejnowski, and Mary B. Kennedy.\n2015. “Computational Reconstitution of Spine Calcium Transients\nfrom Individual Proteins.” Frontiers in Synaptic\nNeuroscience 7. https://www.frontiersin.org/articles/10.3389/fnsyn.2015.00017.\n\n\nBartol, Thomas M., and Joel R Stiles. 2000. Monte Carlo\nMethods for Simulating Realistic Synaptic Microphysiology\nUsing MCell. Vol. chapter 4. CRC Press. https://books.google.com?id=8TLpBwAAQBAJ.\n\n\nBlundon, Jay A., and Stanislav S. Zakharenko. 2008. “Dissecting\nthe Components of Long-Term\nPotentiation.” Neuroscientist 14 (6): 598–608. https://doi.org/10.1177/1073858408320643.\n\n\nBranch, Haley A., Amanda N. Klingler, Kelsey J. R. P. Byers, Aaron\nPanofsky, and Danielle Peers. 2022. “Discussions of the\n‘Not So Fit’: How Ableism Limits Diverse\nThought and Investigative Potential in\nEvolutionary Biology.” The American\nNaturalist 200 (1): 101–13. https://doi.org/10.1086/720003.\n\n\nClaerbout, Jon F., and Martin Karrenbach. 1992. “Electronic\nDocuments Give Reproducible Research a New Meaning.” In\nSEG Technical Program Expanded Abstracts 1992,\n601–4. SEG Technical Program Expanded Abstracts.\nSociety of Exploration Geophysicists. https://doi.org/10.1190/1.1822162.\n\n\nCommunity, The Turing Way, and Scriberia. 2023. Illustrations from\nThe Turing Way: Shared Under\nCC-BY 4.0 for Reuse. Zenodo. https://doi.org/10.5281/zenodo.8169292.\n\n\nDelgado, Nick. 2022. “Owning Your Privilege:\nLeaving Guilt, Shame, and Blame\nBehind.” Integrated Work. February 15, 2022.\nhttps://integratedwork.com/jedi/owning-your-privilege/.\n\n\nDiAngelo, Dr Robin. 2018. White Fragility: Why\nIt’s So Hard for White People to\nTalk About Racism. Beacon Press. https://books.google.com?id=abZdDwAAQBAJ.\n\n\nDiogo, Rui, Adeyemi Adesomo, Kimberly S. Farmer, Rachel J. Kim, and\nFatimah Jackson. 2023. “Not Just in the Past: Racist\nand Sexist Biases Still Permeate Biology, Anthropology, Medicine, and\nEducation.” Evolutionary Anthropology: Issues, News, and\nReviews 32 (2): 67–82. https://doi.org/10.1002/evan.21978.\n\n\nDosi, Giovanni, Luigi Marengo, Jacopo Staccioli, and Maria Enrica\nVirgillito. 2023. “Big Pharma and Monopoly\nCapitalism: A Long-Term View.” Structural Change\nand Economic Dynamics 65 (June): 15–35. https://doi.org/10.1016/j.strueco.2023.01.004.\n\n\nFaeder, James R., Michael L. Blinov, and William S. Hlavacek. 2009.\n“Rule-Based Modeling of Biochemical Systems with\nBioNetGen.” Methods Mol Biol 500: 113–67.\nhttps://doi.org/10.1007/978-1-59745-525-1_5.\n\n\nFennen, Lisa. 2021. Warp & Weft; Psycho-Emotional\nHealth, Politics and Experiences. https://lisafannen.bandcamp.com/album/warp-weft.\n\n\nFink, Charles C., and Tobias Meyer. 2002. “Molecular Mechanisms of\nCaMKII Activation in Neuronal Plasticity.” Curr\nOpin Neurobiol 12 (3): 293–99. https://doi.org/10.1016/s0959-4388(02)00327-6.\n\n\nGarcia, Susana Roman, David Sterratt, and Melanie Stefan. 2022.\n“Thinking about Ethics in (Computer)\nScience.” University of Edinburgh,\nEdinburgh, August 8. https://doi.org/10.5281/zenodo.6973796.\n\n\nGhosh, Anshua, and Karl Peter Giese. 2015.\n“Calcium/Calmodulin-Dependent Kinase II and\nAlzheimer’s Disease.” Molecular Brain 8\n(1): 78. https://doi.org/10.1186/s13041-015-0166-2.\n\n\nGupta, Sanjana, Jacob Czech, Robert Kuczewski, Thomas M. Bartol,\nTerrence J. Sejnowski, Robin E. C. Lee, and James R. Faeder. 2018.\n“Spatial Stochastic Modeling with MCell\nand CellBlender.” September 30, 2018. https://doi.org/10.48550/arXiv.1810.00499.\n\n\nHusar, Adam, Mariam Ordyan, Guadalupe C. Garcia, Joel G. Yancey, Ali S.\nSaglam, James R. Faeder, Thomas M. Bartol, and Terrence J. Sejnowski.\n2022. “MCell4 with BioNetGen: A\nMonte Carlo Simulator of Rule-Based Reaction-Diffusion\nSystems with Python Interface.” May 19, 2022.\nhttps://doi.org/10.1101/2022.05.17.492333.\n\n\nIvie, Peter, and Douglas Thain. 2018. “Reproducibility in\nScientific Computing.” ACM Comput. Surv. 51\n(3): 63:1–36. https://doi.org/10.1145/3186266.\n\n\nKerr, Rex A., Thomas M. Bartol, Boris Kaminsky, Markus Dittrich,\nJen-Chien Jack Chang, Scott B. Baden, Terrence J. Sejnowski, and Joel R.\nStiles. 2008. “FAST MONTE CARLO SIMULATION METHODS FOR\nBIOLOGICAL REACTION-DIFFUSION SYSTEMS IN SOLUTION AND ON\nSURFACES.” SIAM J Sci Comput 30 (6): 3126. https://doi.org/10.1137/070692017.\n\n\nPharris, Matthew C., Neal M. Patel, Tyler G. VanDyk, Thomas M. Bartol,\nTerrence J. Sejnowski, Mary B. Kennedy, Melanie I. Stefan, and Tamara L.\nKinzer-Ursem. 2019. “A Multi-State Model of the\nCaMKII Dodecamer Suggests a Role for Calmodulin in\nMaintenance of Autophosphorylation.” PLOS Computational\nBiology 15 (12): e1006941. https://doi.org/10.1371/journal.pcbi.1006941.\n\n\nPlesser, Hans E. 2018. “Reproducibility Vs.\nReplicability: A Brief History of a\nConfused Terminology.” Frontiers in\nNeuroinformatics 11. https://www.frontiersin.org/articles/10.3389/fninf.2017.00076.\n\n\nRobison, A. J. 2014. “Emerging Role of CaMKII in\nNeuropsychiatric Disease.” Trends in Neurosciences 37\n(11): 653–62. https://doi.org/10.1016/j.tins.2014.07.001.\n\n\nStengers, Isabelle. 2018. Another Science Is\nPossible: A Manifesto for Slow\nScience. John Wiley & Sons. https://books.google.com?id=oxJSDwAAQBAJ.\n\n\nTiwari, Krishna, Sarubini Kananathan, Matthew G. Roberts, Johannes P.\nMeyer, Mohammad Umer Sharif Shohan, Ashley Xavier, Matthieu Maire, et\nal. 2021. “Reproducibility in Systems Biology Modelling.”\nMol Syst Biol 17 (2): e9982. https://doi.org/10.15252/msb.20209982.\n\n\nTreves, Adrian. 2022. “‘Best Available\nScience’ and the Reproducibility Crisis.” Frontiers in\nEcology and the Environment 20 (9): 495–95. https://doi.org/10.1002/fee.2568.\n\n\nTuring Way Community, The, Louise Bowler, Sarah Gibson, Patricia\nHerterich, Rosie Higman, Anna Krystalli, Alexander Morley, Martin\nO’Reilly, and Kirstie Whitaker. 2019. “The Turing\nWay: A Handbook for Reproducible Data\nScience.” Zenodo. https://doi.org/10.5281/zenodo.3233986.\n\n\nWatters, Ethan. 2010. Crazy Like Us: The\nGlobalization of the American Psyche. New\nYork: Free Pr.\n\n\nWebb, E. Kate, J. Arthur Etter, and Jasmine A. Kwasa. 2022.\n“Addressing Racial and Phenotypic Bias in Human Neuroscience\nMethods.” Nat Neurosci 25 (4, 4): 410–14. https://doi.org/10.1038/s41593-022-01046-0.\n\n\nWieber, Frederic, and Alexandre Hocquet. 2020. “Models,\nParameterization, and Software: Epistemic Opacity in Computational\nChemistry.” Published Article or Volume. Perspectives on\nScience; MIT Press. October 2020. https://doi.org/10.1162/posc_a_00352."
  }
]